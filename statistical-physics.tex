\documentclass[]{article}
\usepackage{amssymb,amsmath}
\usepackage{hyperref}

\usepackage{todonotes}
\usepackage[margin=2.5cm]{geometry}
\usepackage[super]{natbib}
\bibliographystyle{unsrtnat}


\title{INFORMATION THEORY AND STATISTICAL MECHANICS}

\author{E. T. JAYNES\\
Washington University}


\begin{document}

BRANDEIS UNIVERSITY SUMMER INSTITUTE\\
LECTURES IN THEORETICAL PHYSICS

K. W. Ford, \emph{\textbf{Editor}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1959}
\item
  Lectures
\end{enumerate}

\begin{quote}
C. Miller • P. T. Matthews • J. Schwinger • N. Fukuda • J. J. Sakurai
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1960}
\item
  \begin{quote}
  Lectures\emph{\textbf{Vol. l}}
  \end{quote}
\end{enumerate}

\begin{quote}
R. J. Eden • J. C. Polkinghorne • G. Källén • J. J.Sakurai
\end{quote}

\emph{\textbf{Vol. 2}}

\begin{quote}
M. E. Rose • E, C. G. Sudarshan
\end{quote}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1961}
\item
  Lectures
\end{enumerate}

\begin{quote}
\emph{\textbf{Vol 1---Elementary Particle Physics and Field Theory}} T.
Fulton • G. Kallen • J. D. Jackson • C. Fronsdal

\emph{\textbf{Vol 2---Astrophysics and ihe Many-Uody Problem}} E. N,
Parker • J. S. Goldstein • A, A. Maiadudin •V. Anibcgaokar

\emph{\textbf{VoL 3---Statistical Physics}} G. E. Uhlenbeck • N.
Rosenzwcig • A. J. F Siegcrt •

E, T. Jaynes • S. Fujita
\end{quote}

Brandeis Summer Institute 1962

STATISTICAL

PHYSICS

3

G. E. Uhlenbeck N. Hosenzweig A, J, F. Siegert E. T. Jaynes S. Fujita

\emph{\textbf{W. A.}} BENJAMIN, INC\emph{\textbf{.}} STATISTICAL PHYSICS

\begin{quote}
1962 Brandeis Lectures in Theoretical Physics, Volume 3

G. E. Uhlenbeck, N. Rosenzweig, A. J. F. Siegert, E. T. Jaynes, and C.
Fujita.
\end{quote}

In his course on SELECTED TOPICS IN STATISTICAL MECHANICS, Professor G.
E. Uhlenbeck begins with an exposition of some diagrammatic methods used
to calculate virial coefficients and the equation of state. He then
gives a detailed analysis of the mathematics of phase transition with a
soluble one-dimensional model.

The second set of lectures, by Dr. N. Rosenzweig, STATISTICAL MECHANICS
OF EQUALLY LIKELY QUANTUM SYSTEMS, is a discussion of the statistical
properties of energy levels and eigenfunctions for heavy nuclei and
complex atoms, stressing the role of time reversal and other symmetries.

Professor A. J. F. Siegert lectures on FUNCTIONAL INTEGRALS IN
STATISTICAL MECHANICS, demonstrating the utility of new techniques by
analysis of the partition function of the Ising model with long range
interactions.

Information theory has provided the long hoped for algorithm analogous
to the partition sum of equilibrium theory, for calculation of
irreversible processes. The lectures of Professor E. T. Jaynes,
INFORMATION THEORY AND STATISTICAL MECHANICS, provide an introduction to
this subject.

In the final set of lectures, Professor C. Fujita reviews and compares
the independent achievements of Van Hove and Prigogine and their
schools, in their progress toward better understanding the APPROACH TO
EQUILIBRIUM OF A MANY-PARTICLE SYSTEM.

\section{Contents}

\tableofcontents

\section{Foreword}

It is now an established tradition of the Brandeis Summer Institute in
Theoretical Physics to have lecturers who present a systematic account
of recent research in various fields of theoretical physics. The lecture
notes have also become a part of tins tradition, and, although these are
sometimes but a first approximation to the spoken lecture, they may
serve to bring these much needed expositions to the wider audience of
physicists who may aspire to contribute to these fields.

I should like to take this opportunity to thank all those whose
participation in the Institute during the summer of 1962 helped maintain
these traditions. Particular words of appreciation are due the National
Science Foundation, for its indispensable financial support, and
Professor Kenneth Ford, who graciously carried the responsibility for
getting the notes ready for publication.

In this volume, the notes of Professor Jaynes and Professor Fujita have
been prepared by the lecturers; Professor Uhlenbeck, Dr. Rosenzweig, and
Professor Siegert have kindly checked over the notes based on their
lectures.

\begin{quote}
\emph{\textbf{\textsc{David L. Falkoff}}} Co-Director of the
\emph{\textbf{1962}} Institute

\maketitle 

Notes by the lecturer

\tableofcontents

\section{INTRODUCTION}\label{introduction}

At the beginning of every problem in probability theory, there arises a
need to assign some initial probability distribution; or what is the
same thing, to ``set up an ensemble.'' This is a problem which cannot be
evaded, and for which the laws of physics give us no help. For example,
the laws of physics tell us that a density matrix
\(\rho\left( t \right)\) must vary with time according to
\(\dot{\rho\left( t \right) = \lbrack H,\rho\rbrack}\), but they do not
tell us what function \(\rho(0)\) should be put in at the start.
Assignment of \(\rho(0)\) is, of course, a matter of free choice on our
part---it is for us to say which problem we want to solve.

The assignment of initial probabilities must, in order to be useful,
agree with the initial information we have (i.e., the results of
measurements of certain parameters). For example, we might know that at
time \(t = 0\), a nuclear spin system having total (measured) magnetic
moment \(M(0)\), is placed in a magnetic field \(H\), and the problem is
to predict the subsequent variation \(M(t)\), which presumably tends to
an equilibrium value \(M\left( \infty \right) = x_{0}H\) after a long
time. What initial density matrix for the spin system \(\rho(0)\),
should we use? Evidently, we shall want it to satisfy, at the very
least,

\[\text{Tr}\left( \rho(0)M_{o_{p}} \right) = M(0)\]

where \(M \ll p\) moment. But Eq. (1) is very far from uniquely
specifying \(\rho(0)\)p. Out of the infinite number of density matrices
satisfying (1), which should we choose as the starting point of our
calculation to predict \(M(t)\)?

Conventional quantum theory has provided an answer to the problem of
setting up initial state descriptions only in the limiting case where
measurements of a "complete set of commuting observables" have been
made, the density matrix \(\rho(0)\) then reducing to the projection
operator onto a pure state \(\psi(0)\) which is the appropriate
simultaneous eigenstate of all the measured quantities. But there is
almost no experimental situation in which we really have all this
information, and before we have a theory able to treat actual
experimental situations, existing quantum theory must be supplemented
with some principle that tells us how to translate, or encode, the
results of measurements into a definite state description \(\rho(0)\).
Note that the problem is not to find the \(\rho(0)\) which correctly
describes the "true physical situation." That is unknown, and always
remains so, because of incomplete information. In order to have a usable
theory we must ask the much more modest question: "What \(\rho(0)\) best
describes our \emph{state of knowledge} about the physical situation?"

In order to emphasize that this problem really has nothing to do with
the laws of physics (and, as a corollary, that its solution will have
applications outside the field of physics), consider the following
problem. A die has been tossed a very large number \(N\) of times, and
we are told that the \emph{average} number of spots up per toss was not
3.5, as we might expect from an honest die, but 4.5. Translate this
information into a probability assignment
\(P_{n},n = 1,\ 2,\ \ldots,6\), for the \(n\)th face to come up on the
next toss.

To explain more fully what is meant by this, note that we are not asking
for an estimate of the fraction (i.e., the relative frequency) of tosses
which give \(n\) spots There is, indeed, a connection between the
probability and the frequency, which we will derive later. But the
problem stated is to reason as best we can about the \emph{individual}
case. The probability \(P_{n}\) must therefore be interpreted in the
so-called "subjective" sense; it is only a means of describing how
strongly we \emph{believe} that the \(n\)-th face will come up in the
next toss.

To state the problem more drastically, imagine that we are offered
several bets, at various odds, on various values of \(n\), and we are
compelled to accept one of these bets. The probabilities \(P_{n}\) are
the basic raw material from which we decide which one to accept. This is
typical of many practical problems faced by the scientist, the engineer,
the statistician, the politician; and indeed all of us. We are
continually faced with situations where some definite decision must be
made \emph{now}, even though we do not have all the information we might
like.

\[{\sum_{n = 1}^{6}\mspace{2mu} P_{n} = 1
}{\sum_{n = 1}^{6}\mspace{2mu} nP_{n} = 4.5}\]

\includegraphics[width=3.20866in,height=1.75197in]{media/image1.jpeg}\includegraphics[width=3.16142in,height=2in]{media/image2.png}where
(3) is analogous to (1). A possible solution of (2) and (3) is indicated
in Fig. 1; we could take \(P_{4} = P_{5} = 1/2\), all other
\(P_{n} = 0\), This agrees with all the given data. But our common sense
tells us it is not a \emph{reasonable} assignment. The assignment of
Fig. 2 is evidently a more honest description of what we know. But even
this is not reasonable---nothing in the data tells us that n = 1, 2 are
impossible events. In Fig. 2, we are still jumping to conclusions not
warranted by the available evidence. Evidently, it is unreasonable to
assign probability zero to any situation unless our data really rules
out that case. If we assign \(P_{1} > 0\), \(P_{2} > 0\), then in order
to keep the average at 4.5, we shall have to give some increased weight
to the cases \(n = 5,\ 6\). Figure 3 shows an assignment that agrees
with the data and does not ignore any possibility. But it still seems
unreasonable to give the case \(n = 6\) such exceptional treatment.
Figure 4 represents what we should probably call a
\includegraphics[width=3.39764in,height=1.64567in]{media/image3.jpeg}backward
step---nothing in the data of the problem indicates any reason for such
an uneven treatment. A reasonable assignment \(P_{n}\) must not only
agree with the data and must not ignore any
\includegraphics[width=2.71319in,height=1.81042in]{media/image4.jpeg}possibility---but
it must also not give undue emphasis to any possibility. The \(P_{n}\)
should vary as smoothly as possible, in some sense. One criterion of
"smoothness" might be that adjacent differences \(P_{n + 1} - P_{n}\)
should be constant; and, indeed, there is a solution with that property.
It is given by \(P_{n} = (12n - 7)/210\) and
\includegraphics[width=2.48031in,height=1.82283in]{media/image5.jpeg}is
shown in Fig. 5. This is evidently the most reasonable probability
assignment so far. But there is a limit to how high an average you can
get with this linear variation of \(P_{n}\). If we took the extreme
case, \(P_{n} = (const.)(n - 1)\), we should again violate one of our
principles because \(P_{1} = 0\), and the average would be only
\(\sum_{n}^{}{P_{n} = 70/15} = 4.67\). Suppose the data of the problem
had been changed so that the average is to be 4.7 instead of 4.5. Then
there is no straight-line solution satisfying \(P_{n} \geq 0\). The
\(P_{n}\) must lie on some concave curve, as in Fig. 6. But the
principles by which we reason
surely\includegraphics[width=3.16535in,height=1.84252in]{media/image6.jpeg}
are the same whether the data specify 4.5 or 4.7; so it appears that a
result qualitatively such as Fig. 6 should be used also when
\(n = 4.5\).

\[S_{I} = - \sum_{i}^{}\mspace{2mu} p_{i}\log p_{i}
\]


\section{THE GENERAL MAXIMUM-ENTROPY FORMALISM}\label{the-general-maximum-entropy-formalism}

To generalize the above problem somewhat, suppose that the quantity
\(x\) can take on the values \((\_ 1\ \)(x\textsubscript{1\}}
x\textsubscript{2},. .., x\textsubscript{n}) where n can be finite or
infinite, and that the average values of several functions fjtx),
f\textsubscript{2}(x),..., f\textsubscript{m}(x) are given, where m
\textless{} n. The problem is to find the probability assignment pj =
p(xj) which satisfies the given data: pj \textgreater{} 0,

\[\sum_{i = 1}^{n}\mspace{2mu} p_{i} = 1\]

\[\sum_{i = 1}^{n}\mspace{2mu} p_{i}f_{k}\left( x_{i} \right) = \left\langle f_{k}(x) \right\rangle = F_{k}k = 1,2,\ldots,m\]

and, subject to (5) and (6), maximizes the entropy

\[S_{I} = - \sum_{i = 1}^{n}\mspace{2mu} p_{i}\log p_{1}\]

The solution to this mathematical problem can be found immediately by
the method of Lagrangian multipliers, and special cases are given in
every statistical mechanics textbook. This method has the merit that it
leads immediately to the answer, but the weakness that it does not make
it obvious whether one obtains a true absolute maximum of \(S_{I}\). The
following argument establishes this important result more rigorously.
Let \(\left( p_{1}\ldots p_{n} \right)\) and
\(\left( u_{1}\ldots u_{n} \right)\) be any two possible probability
distributions over the \(x_{1};\) i.e.,
\(p_{i} \geq 0,u_{i} \geq 0,i = 1,2,\ldots\) n and

\[\sum_{i = 1}^{n}\mspace{2mu} p_{1} = \sum_{i = 1}^{n}\mspace{2mu} u_{i} = 1\]

\(S_{I}\)Then, by using the fact that
\(logx \geq \left( 1 - x^{- 1} \right),\) with equality if and only if
\(x = 1,\) we find the following:

Lemma

\[\sum_{i = 1}^{n}\mspace{2mu} p_{i}log\frac{p_{i}}{u_{i}} \geq \sum_{i = 1}^{n}\mspace{2mu} p_{i}\left( 1 - \frac{u_{i}}{p_{i}} \right) = 0\]

with equality if and only if \(p_{i} = u_{i},i = 1,2,\ldots n\). Now
make the choice

\[u_{i} = \frac{1}{Z\left( \lambda_{1}\ldots\lambda_{m}) \right.\ }exp\left( - \lambda_{1}f_{1}\left( x_{i} \right) - \ldots - \lambda_{m}f_{m}\left( x_{i} \right) \right)\]

where \(\lambda_{1}\ldots\lambda_{m}\) are fixed constants, and

\[Z\left( \lambda_{1}\ldots\lambda_{m} \right) \equiv \sum_{i = 1}^{n}\mspace{2mu} exp\left( - \lambda_{1}f_{1}\left( x_{1} \right) - \ldots - \lambda_{m}f_{m}\left( x_{i} \right) \right)\]

will be called the ``partition function.'' Substituting (10) into (9)
results in the inequality

\[\begin{matrix}
\sum_{i = 1}^{n}\mspace{2mu}\mspace{2mu} p_{i}logp_{i} \geq \sum_{i = 1}^{n}\mspace{2mu}\mspace{2mu} p_{i}logu_{i} = & \  - \sum_{i = 1}^{n}\mspace{2mu}\mspace{2mu} p_{i}\left\lbrack \lambda_{1}f_{1}\left( x_{i} \right) + \ldots \right.\  \\
 & \left. \  + \lambda_{m}f_{m}\left( x_{i} \right) \right\rbrack - logZ\left( \lambda_{1}\ldots\lambda_{m} \right) \\
\end{matrix}\]

or

\[s_{1} \leq logZ\left( \lambda_{1}\ldots\lambda_{m} \right) + \sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\left\langle f_{k} \right\rangle\]

Now let the distribution \(p_{1}\) vary over the class of all possible
distributions that satisfy (6). The right-hand side of (12) remains
fixed, and (12) shows that \(S_{1}\) attains itsmaximum possible value

\[\left( S_{I} \right)_{\max} = logZ + \sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\left\langle f_{k} \right\rangle\]

if and only if \(p_{i}\) is taken as the generalized canonical
distribution\\
(10). It only remains to choose the unspecified constants
\(\lambda_{k}\) so that (6) is satisfied. This is the case, as one
readily verifies, if the \(\lambda_{k}\) are determined in terms of the
given data \(F_{k} = \left\langle f_{k} \right\rangle\) by

\[\left\langle f_{k} \right\rangle = - \frac{\partial}{\partial\lambda_{k}}logZ\left( \lambda_{1}\ldots\lambda_{m} \right)\ k = 1,2,\ldots,m\]

We now survey rapidly the main formal properties of the distribution
found. The maximum attainable entropy (13) is some function of the given
data:

\[\left( S_{I} \right)_{\max} = S\left( \left( f_{2} \right),\ldots\left\langle f_{m} \right\rangle \right)\]

and, by using (13) and (14), we find

\[\frac{\partial S}{\partial\left\langle f_{k} \right\rangle} = \lambda_{k}\ k = 1,2,\ldots,m\]

Regarding, in (14), the \(\left\langle f_{k} \right\rangle\) expressed
as functions of \(\left( \lambda_{1}\ldots\lambda_{m} \right)\) we find,
on differentiating, the reciprocity law

\[\frac{\partial\left\langle f_{k} \right\rangle}{\partial\lambda_{j}} = \frac{\partial\left\langle f_{j} \right\rangle}{\partial\lambda_{k}} = - \frac{\partial^{2}}{\partial\lambda_{k}\partial\lambda_{j}}logZ = A_{\text{jk}}\]

while by the same argument, if we regard \(\lambda_{k}\) in (16)
expressed as

a function of
\(\left\langle f_{1} \right\rangle\ldots\left\langle f_{m} \right\rangle,\)
we find a corresponding law

\[\frac{\partial\lambda_{k}}{\partial\left\langle f_{j} \right\rangle} = \frac{\partial\lambda_{j}}{\partial\left\langle f_{k} \right\rangle} = \frac{\partial^{2}S}{\partial\left\langle f_{j} \right\rangle\partial\left\langle f_{k} \right\rangle} = B_{\text{jk}}\]

Comparing (17) and (18) and remembering the chain rule for
differentiating,

\[\frac{\partial\left\langle f_{j} \right\rangle}{\partial\left\langle f_{k} \right\rangle} = \sum_{\mathcal{l}}^{}\mspace{2mu}\frac{\partial\left\langle f_{j} \right\rangle}{\partial\lambda_{\mathcal{l}}}\frac{\partial\lambda_{\mathcal{l}}}{\partial\left\langle f_{k} \right\rangle} = \delta_{\text{jk}}\]

we see that the second derivatives of \(S\) and of log \(Z\) yield
inverse matrices:

\[A = B^{- 1}\]

The functions \(logZ\left( \lambda_{1}\ldots\lambda_{n} \right)\) and
\(S\left( \left\langle f_{1} \right\rangle\ldots\left\langle f_{n} \right\rangle \right)\)
are equivalent in the sense that each gives full information about the
probability distribution; indeed (13) is just the Legendre
transformation that takes us from one representative function to the
other.

The reciprocity law (17) acquires a deeper meaning when we consider the
``fluctuations'' in our probability distribution. Using the distribution
(10), a short calculation shows that the second central moments of the
distribution of the \(f_{k}(x)\) are given by

\[\begin{matrix}
\left\langle \left( f_{k} - \left\langle f_{k} \right\rangle \right)\left( f_{\mathcal{l}} - \left\langle f_{\mathcal{l}} \right\rangle \right) \right\rangle = \left\langle f_{k}f_{\mathcal{l}} \right\rangle & \  - \left\langle f_{k} \right\rangle\left\langle f_{\mathcal{l}} \right\rangle \\
 = & \frac{\partial^{2}}{\partial\lambda_{k}\partial\lambda_{\mathcal{l}}}logZ \\
\end{matrix}\]

and so, comparing with (17) , there is a universal relation between the
``fluctuations'' of the \(f_{k}\) and the ``compliance coefficients''
\(\partial\left\langle f_{k} \right\rangle/\partial\lambda_{\mathcal{l}}:\)

\[\left\langle f_{k}f_{l} \right\rangle - \left\langle f_{k} \right\rangle\left\langle f_{\mathcal{l}} \right\rangle = - \frac{\partial\left\langle f_{k} \right\rangle}{\partial\lambda_{\mathcal{l}}} = - \frac{\partial\left\langle f_{\mathcal{l}} \right\rangle}{\partial\lambda_{k}}\]

Likewise, higher derivatives of
\(logZ\left( \lambda_{1}\ldots\lambda_{n} \right)\) yield higher central
moments of the \(f_{k}\), in a manner analogous to (20), and a hierarchy
of fluctuation laws similar to (21).

In addition to their dependence on \(x\), the functions \(f_{k}\) may
depend on another parameter, \(\alpha.\) The partition function will
then also have an explicit dependence on \(\alpha\) :

\[Z\left( \lambda_{1}\ldots\lambda_{m};\alpha \right) \equiv \sum_{i = 1}^{n}\mspace{2mu} exp\left( - \lambda_{1}f_{1}\left( x_{i};\alpha \right) - \ldots - \lambda_{m}f_{m}\left( x_{i};\alpha \right) \right)\]

and a short calculation shows that the expected derivatives

\[\left\langle \frac{\partial f_{k}}{\partial\alpha} \right\rangle\]

satisfy the relations

\[\sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\left\langle \frac{\partial f_{k}}{\partial\alpha} \right\rangle = - \frac{\partial}{\partial\alpha}logZ = - \frac{\partial S}{\partial\alpha}\]

If several parameters \(\alpha_{1}\ldots\alpha_{r}\) are present, a
relation of this form will hold for each of them.

Finally, we note an important variational property which generalizes
(16) to the case where we have also variations in the parameters
\(\alpha_{1}\ldots\alpha_{r}.\) Let
\(Z = Z\left( \lambda_{1}\ldots\lambda_{m};\alpha_{1}\ldots\alpha_{r} \right),\)
and consider an arbitrary small change in the problem, where the given
data \(\left\langle f_{k} \right\rangle\) and the parameters
\(\alpha_{j}\) are changed by small amounts
\(\delta\left\langle f_{k} \right\rangle/\delta\alpha_{j}\) This will
lead to a change \(\delta\lambda_{k}\) in \(\lambda_{k}\). From (13),
the maximum attainable entropy is changed by

\[\begin{matrix}
\text{sS} = & \ \sum_{k = 1}^{m}\mspace{2mu}\mspace{2mu}\frac{\partial logZ}{\partial\lambda_{k}}\delta\lambda_{k} + \sum_{j = 1}^{r}\mspace{2mu}\mspace{2mu}\frac{\partial logZ}{\partial\alpha_{j}}\delta\alpha_{j} \\
 & \  + \sum_{k = 1}^{m}\mspace{2mu}\mspace{2mu}\left\langle f_{k} \right\rangle\delta\lambda_{k} + \sum_{k = 1}^{m}\mspace{2mu}\mspace{2mu}\lambda_{k}\delta\left\langle f_{k} \right\rangle \\
\end{matrix}\]

The first and third terms cancel by virtue of (14). Then, using (23), we
have

\[\text{δS} = - \sum_{j = 1}^{r}\mspace{2mu}\sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\left\langle \frac{\partial f_{k}}{\partial\alpha_{j}} \right\rangle\delta\alpha_{j} + \sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\delta\left\langle f_{k} \right\rangle\]

Now we can write

\[\sum_{j = 1}^{r}\mspace{2mu}\left\langle \frac{\partial f_{k}}{\partial\alpha_{j}} \right\rangle\delta\alpha_{j} = \left\langle \sum_{j = 1}^{r}\mspace{2mu}\mspace{2mu}\frac{\partial f_{k}}{\partial\alpha_{j}}\delta\alpha_{j} \right\rangle = \left\langle \delta f_{k} \right\rangle\]

and so finally

\[\text{δS} = \sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\left\lbrack \delta\left( f_{k} \right\rangle - \left\langle \delta f_{k} \right\rangle \right\rbrack\]

or

\[\text{δS} = \sum_{k = 1}^{m}\mspace{2mu}\lambda_{k}\delta Q_{k}\]

where

\[\delta Q_{k} \equiv \delta\left\langle f_{k} \right\rangle - \left\langle \delta f_{k} \right\rangle\]

In general \(\delta Q_{k}\) is not an exact differential; i.e., there is
no function
\(Q_{k}\left( \lambda_{1}\ldots\lambda_{m};\alpha_{1}\ldots\alpha_{r} \right)\)
which yields \(\delta Q_{k}\) by differentiation. But (28) shows that
\(\lambda_{k}\) is an integrating factor such that
\(\sum_{k}\mspace{2mu}\lambda_{k}\delta Q_{k}\) is the exact
differential of some ``state function''
\(S\left( \lambda_{1}\cdots\lambda_{m};\alpha_{2}\cdots\alpha_{r} \right)\).

All the above relations, (10) to (29), are elementary consequences of
maximizing the information theory entropy subject to constraints on
average values of certain quantities. Although they bear a strong formal
resemblance to the rules of calculation provided by statistical
mechanics, they make no reference to physics, and, therefore, they must
apply equally well to any problem, in or out of physics, where the
situation can be described by (1) enumerating a discrete set of
possibilities and by (2) specifying average values of various
quantities. The above formalism has been applied also to problems in
engineering\footnote{E. T. Jaynes, Note on unique decipherability, IRE
  Trans. Inform. Theory, Sept. 1959.} and economics.\footnote{E, T.
  Jaynes, New engineering applications of information theory, in
  '\,'Symposium on Engineering Applications of Random Function Theory
  and Probability" (J. L. Bogdanoff and F. Kozin, eds.), Wiley, New
  York, 1963.}

In most problems, interest centers on making the best possible
predictions for a \emph{specific} situation, and we are not really
interested in properties of any ensemble, real or imaginary. (For
example, we want to predict the magnetization \(M(t)\) of the
\emph{particular} spin system that exists in the laboratory.) In this
case, as already emphasized, the maximum-entropy probability assignment
\(p_{i}\) cannot be regarded as describing any objectively existing
state of affairs; it is only a means of describing a state of knowledge
in a way that. is ``maximally noncommital'' by a certain criterion.

The above equations then represent simply the best predictions we are
able to make on the given information. We are not entitled to assert
that the predictions must be ``right,'' only that to make any better
ones, we should need more information than was given. However, in cases
where it makes sense to imagine \(x_{i}\) as being the result of some
random experiment which can be repeated many times, a somewhat more
``objective'' interepretation of this formalism is possible, which in
its essentials was given already by Boltzmann. We are given the same
average values \(\left\langle f_{k}(x) \right\rangle\) as before, but we
are now asked a different question. If the random experiment is repeated
\(N\) times, the result \(x_{i}\) will be obtained \(m_{i}\) times,
\(1 = 1,2,\ldots,n,\) We are to make the best estimates of the numbers
\(m_{i}\) on the basis of this much information. The knowledge of
average values tells us that

\[\sum_{i = 1}^{n}\mspace{2mu}\frac{m_{i}}{N}f_{k}\left( x_{i} \right) = \left\langle f_{k} \right\rangle\ k = 1,2,\ldots,m\]

and, of course,

\[\sum_{i = 1}^{n}\mspace{2mu}\frac{m_{i}}{N} = 1\]

Equations (30) and (31) do not uniquely determine the \(m_{i}\) if
\(m < n - 1,\) and so again it is necessary to introduce some additional
principle, which now amounts to stating what we mean by the ``best''
estimate. The following criterion seems reasonable. In \(N\) repetitions
of the random experiment, there are \emph{a priori} \(n^{N}\)
conceivable results, since each trial could give independently any of
the results \(\left( x_{1},x_{2},\ldots,x_{n} \right)\). But for given
\(m_{i}\), there are only \(W\) of these possible, where

\[W \equiv \frac{N!}{m_{1}!\ldots m_{n}!} = \frac{N!}{\left( Ng_{1} \right)!\left( Ng_{2} \right)!\ldots\left( Ng_{n} \right)!}\]

and

\[g_{i} = \frac{m_{i}}{N}\ i = 1,2,\ldots,n\]

is the relative frequency with which the result \(x_{i}\) is obtained.
Which cholce of the \(g_{1}\) can happen in the greatest number of ways?
If we have to guess the frequencies on the basis of no more information
than \((30),\) it seems that a reasonable criterion is to ask what
choice will maximize (32) while agreeing with (30). Now in the limit of
large \(N\), we have by the Stirling formula,

\[\begin{matrix}
\lim_{N \rightarrow \infty}\mspace{2mu}\frac{1}{N}logW & \  = \lim_{N \rightarrow \infty}\mspace{2mu}\frac{1}{N}log\left\lbrack \frac{N!}{\left( Ng_{1} \right)!\ldots\left( Ng_{n} \right)!} \right\rbrack \\
 & \  = - \sum_{i = 1}^{n}\mspace{2mu}\mspace{2mu} g_{i}logg_{i} \\
\end{matrix}\]

and so, if we are to estimate limiting frequencies in an indefinitely
large number of trials, we have in (30) and (34) formulated exactly the
same mathematical problem as in (6) and (7). The same solution (10) and
formal properties, Eqs, (11) to (29), follow immediately, and we have an
alternative interpretation of the maximum-entropy formalism: the
probability \(p_{i}\) which information theory assigns to the event
\(x_{i}\) at a \emph{single} trial is numerically equal to an estimate
of the relative frequency \(g_{1}\) of this result in an indefinitely
large number of trials, obtained by enumerating all cases consistent
with our knowledge, and placing our bets on the situation that can
happen in the greatest number of ways. Thus, for example, the
fluctuation laws (21) describe, on the one hand, our uncertainty as to
the unknown true values of \(f_{k}(x)\) in a specific instance; on the
other hand, they give the best estimates we can make of the
\emph{average} departures from \(\left\langle f_{k} \right\rangle\) in
many repetitions of the experiment, by the criterion of placing our bets
on the situation that can happen in the greatest number of ways. Two
points about these interpretations should be noted:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  In most practical problems, repeated repetition of the experiment is
  either impossible or not relevant to the real problem, which is to do
  the best we can with the \emph{individual} case. Thus if one were to
  insist, as has sometimes been done, that only the second
  interpretation is valid, the result would be to deny ourselves the use
  of this formalism in most of the problems where it is helpful.
\item
  The argument leading from the averages (30) to the estimate of
  frequencies \(g_{i}\) was not deductive reasoning, but only plausible
  reasoning. Consequently, we are not entitled to assert that the
  estimates \(g_{i}\) \emph{must} be right; only that, in order to make
  any better estimates, we should need more information. Thus the
  apparently greater ``objectivity'' of the second interpretation is to
  a large extent illusory.
\end{enumerate}

\end{document}
